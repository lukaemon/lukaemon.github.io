<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.280">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Lucas Shen">
<meta name="dcterms.date" content="2023-04-01">
<meta name="description" content="My takeaway of gpt4 release">

<title>Lucas Shen - On GPT4</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>


<script src="../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../">
<link href="../../../asset/favicon.jpg" rel="icon" type="image/jpeg">
<script src="../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../../site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>


<meta property="og:title" content="Lucas Shen - On GPT4">
<meta property="og:description" content="My takeaway of gpt4 release">
<meta property="og:image" content="https://lukaemon.github.io/posts/2023/on-gpt4/cover.png">
<meta property="og:site-name" content="Lucas Shen">
<meta property="og:image:height" content="896">
<meta property="og:image:width" content="1344">
<meta name="twitter:title" content="Lucas Shen - On GPT4">
<meta name="twitter:description" content="My takeaway of gpt4 release">
<meta name="twitter:image" content="https://lukaemon.github.io/posts/2023/on-gpt4/cover.png">
<meta name="twitter:image-height" content="896">
<meta name="twitter:image-width" content="1344">
<meta name="twitter:card" content="summary_large_image">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../../index.html">
    <span class="navbar-title">Lucas Shen</span>
    </a>
  </div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../../about.html">
 <span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/lukaemon"><i class="bi bi-github" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/luka_emon"><i class="bi bi-twitter" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="../../../index.xml"><i class="bi bi-rss" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
              <div class="quarto-toggle-container">
                  <a href="" class="quarto-color-scheme-toggle nav-link" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
              </div>
              <div id="quarto-search" class="" title="Search"></div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">On GPT4</h1>
                  <div>
        <div class="description">
          My takeaway of gpt4 release
        </div>
      </div>
                          <div class="quarto-categories">
                <div class="quarto-category">opinion</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Lucas Shen </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">April 1, 2023</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#context" id="toc-context" class="nav-link active" data-scroll-target="#context">Context</a></li>
  <li><a href="#tldr" id="toc-tldr" class="nav-link" data-scroll-target="#tldr">tl;dr</a></li>
  <li><a href="#breakthrough" id="toc-breakthrough" class="nav-link" data-scroll-target="#breakthrough">Breakthrough</a>
  <ul class="collapse">
  <li><a href="#world-model" id="toc-world-model" class="nav-link" data-scroll-target="#world-model">World model</a></li>
  <li><a href="#self-improvement-with-rlhf" id="toc-self-improvement-with-rlhf" class="nav-link" data-scroll-target="#self-improvement-with-rlhf">Self improvement with RLHF</a></li>
  </ul></li>
  <li><a href="#future" id="toc-future" class="nav-link" data-scroll-target="#future">Future</a>
  <ul class="collapse">
  <li><a href="#research" id="toc-research" class="nav-link" data-scroll-target="#research">Research</a></li>
  <li><a href="#human-ai-symbiosis" id="toc-human-ai-symbiosis" class="nav-link" data-scroll-target="#human-ai-symbiosis">Human-AI symbiosis</a></li>
  </ul></li>
  <li><a href="#outro" id="toc-outro" class="nav-link" data-scroll-target="#outro">Outro</a></li>
  </ul>
<div class="toc-actions"><div><i class="bi bi-github"></i></div><div class="action-links"><p><a href="https://github.com/lukaemon/lukaemon.github.io/blob/main/posts/2023/on-gpt4/index.qmd" class="toc-action">View source</a></p></div></div></nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block page-columns page-full" id="quarto-document-content">




<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="cover.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption margin-caption">MJ: abstract art, artificial general intelligence –ar 3:2 –v 5. This generation is interesting. It captures the shape of vector space, which is the foundation of modern AI. The shape at the center is more ordered, well organized, but blurry and chaotic close to the edge.</figcaption><p></p>
</figure>
</div>
<section id="context" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="context">Context</h2>
<p>At first glance, gpt4 is 80% fear and 20% excitement. I’m afraid of its capability, impact to the future of work, and worried about advanced intelligence being controlled by single organization.</p>
<p>However, fear is not real. Danger is. Fear is a mental construct mostly caused by ignorance. In hope to cure the ignorance, I go on studying and using gpt4. After few weeks of processing, the fear subsides. I have better understanding of gpt4’s capability, limitation, risk and the future.</p>
<div class="page-columns page-full"><p>The sheer existence of GPT4 is pivotal to me. It is a wake up call: be prepared to live with AI at all level. I believe GPT4 is pivotal to the society as well. Prepared or not, AI is coming. Open letter<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> like this won’t slow it down, but accelerate. The letter basically validates the hype and few rounds of clickbait journalism and doom hyper would fuel the fear. Leading AI companies would have to handle AI R&amp;D as scientific discovery and political campaign in the post-GPT4 era. AI is political and even more so from now on.</p><div class="no-row-height column-margin column-container"><li id="fn1"><p><sup>1</sup>&nbsp;<a href="https://futureoflife.org/open-letter/pause-giant-ai-experiments">Pause Giant AI Experiments: An Open Letter</a></p></li></div></div>
<p>Here is my opinion and I won’t bother to be neutral. I could be wrong and I am ready to be.</p>
</section>
<section id="tldr" class="level2">
<h2 class="anchored" data-anchor-id="tldr">tl;dr</h2>
<p>My understanding of gpt4 is mostly based on 3 papers and 2 videos. Info per token is so high that requires few rounds of study to fully grasp all nuances from these sources. Here are the most important lesson learned from each. The following article would expand on few points.</p>
<ul>
<li><strong>Sparks of Artificial General Intelligence: Early experiments with GPT-4</strong> <span class="citation" data-cites="bubeckSparksArtificialGeneral2023">(<a href="#ref-bubeckSparksArtificialGeneral2023" role="doc-biblioref">Bubeck et al. 2023</a>)</span>.
<ul>
<li>Traditional benchmarks are not enough. They fail to capture semantic similarities within statements, and rely primarily on word or sentence-level similarity metrics which capture syntax.</li>
<li>Pure text autoregressive model could learn visual representation and more.</li>
<li>Natural language and code are more controllable than pixels. Symbolic intermediate layer could be useful proxy to high dim modality manipulation. Ex: <code>fn(text) -&gt; image: text -&gt; code -&gt; well controlled skeleton sketch -&gt; super resolution</code>.</li>
<li>CoT is linear decomposition. Useful but not enough. To express loop, recursion and more complex reasoning, multistep modification of scratchpad is helpful. Could use one agent’s context window as scratchpad, aka RAM, and retrieval system as HD. The multi-agent organization to approx system 2 thinking would be an interesting research direction.</li>
<li>The limitations of the next-word prediction paradigm, which manifest as the model’s lack of planning, working memory, ability to backtrack, and reasoning abilities. The model relies on a local and greedy process of generating the next word, without any global or deep understanding of the task or the output.</li>
<li>Current level AI is good at incremental tasks, while human could be good at discontinuous tasks.</li>
</ul></li>
<li><strong>GPT-4 technical report</strong> <span class="citation" data-cites="GPT4TechnicalReport">(<a href="#ref-GPT4TechnicalReport" role="doc-biblioref"><span>“<span>GPT-4</span> Technical Report”</span> 2023</a>)</span>.
<ul>
<li>The danger is real. Powerful AI is harder to align.</li>
<li>Threshold crossed. GPT4 is good enough to contribute substantially to self-improvement. GPT3.5 is not as helpful.</li>
<li>RL acts as information bottleneck, which is a form of regulation for better generalization. Apply RL on gpt4 is effective finetuning, contrary to traditional understanding of sample inefficiency due to RL’s sparse feedback. The order to cook intelligence matters.</li>
</ul></li>
<li><strong>GPTs are GPTs: An Early Look at the Labor Market Impact Potential of Large Language Models</strong> <span class="citation" data-cites="eloundouGPTsAreGPTs2023">(<a href="#ref-eloundouGPTsAreGPTs2023" role="doc-biblioref">Eloundou et al. 2023</a>)</span>.
<ul>
<li>Occupation exposure is not important. Jobs would change dramatically in the future. Go first principle to skill level exposure.</li>
<li>Focus resource and time on developing skills that humans have chance to do better than AI. ex: science and critical thinking.</li>
</ul></li>
<li><strong>Fireside Chat with Ilya Sutskever and Jensen Huang: AI Today and Vision of the Future</strong> <span class="citation" data-cites="sutskeverFiresideChatIlya2023">(<a href="#ref-sutskeverFiresideChatIlya2023" role="doc-biblioref">Sutskever and Huang 2023</a>)</span>.
<ul>
<li>Autoregressive model on text is more than statistical token joint distribution. Text is one projection of the world. Learning from text is approximate the world thought a projection, which is essentially learning a world model.</li>
<li>Learning from text is effective but not enough. Multimodal model would be more powerful and sample efficient. Scaling text model is not all you need.</li>
</ul></li>
<li><strong>Sam Altman: OpenAI CEO on GPT-4, ChatGPT, and the Future of AI | Lex Fridman Podcast #367</strong> <span class="citation" data-cites="lexfridmanSamAltmanOpenAI2023">(<a href="#ref-lexfridmanSamAltmanOpenAI2023" role="doc-biblioref">Lex Fridman 2023</a>)</span>.
<ul>
<li>We learned early on that we need way more capital that won’t be able to raised as non-profit.</li>
<li>We need some benefits of capitalism but not too much. As a non-profit, nothing would happen. As a for-profit, too much would happen.</li>
</ul></li>
</ul>
<p>The following topics are <strong>not important</strong> to <strong>advance the frontier of AI</strong>. Learning to ignore is as useful as learning to pay attention given specific goal. Both are the process of cultivating taste, which is the first pass filter and ultimately decides the direction of change.</p>
<ul>
<li><strong>SOTA benchmarks. Bar, SAT, GRE, AP test score</strong>: traditional benchmarks are like IQ for human. We all know they are deeply flawed but because these numbers are so relatable, we are not ready to let go. I treat them as quick and dirty AI unit tests and no more. Bar and SAT are great PR creator. Kudos to that.</li>
<li><strong>Training data leak to eval</strong>: getting this right is important to do good science, but don’t waste too much time on this since those benchmarks are not important anymore.</li>
<li><strong>OpenAI is not open. Details of architecture, training and data are not published</strong>: I hope they transition to <a href="https://ai.com/">ai.com</a> as soon as possible to close this boring thread. Pure waste of bits.</li>
<li><strong>Whether gpt4 is AGI</strong>: all models are wrong, some could be useful. Intelligence is getting cheaper and cheaper. Risks and promises are closing in. Move on.</li>
<li><strong>Small distilled model on iPhone</strong>: this could be very impactful applied AI, but has nothing to do with the frontier.</li>
</ul>
</section>
<section id="breakthrough" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="breakthrough">Breakthrough</h2>
<ul>
<li>GPT4 learns a world model from text.</li>
<li>GPT4 conquers few more bits in the semantics realms to cross the threshold of being useful for self-improvement.</li>
</ul>
<p>These breakthroughs fuel the excitement about the possibility of multimodal modal research, and the self-play moment for general AI, similar sentiment of AlphaZero <span class="citation" data-cites="silverMasteringChessShogi2017">(<a href="#ref-silverMasteringChessShogi2017" role="doc-biblioref">Silver et al. 2017</a>)</span> to Go. Are we already on the artificial intelligence super highway?</p>
<section id="world-model" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="world-model">World model</h3>
<p>To me, gpt4 is as impactful, if not more, as gpt3 <span class="citation" data-cites="brownLanguageModelsAre2020">(<a href="#ref-brownLanguageModelsAre2020" role="doc-biblioref">Brown et al. 2020</a>)</span>. Before gpt3, people finetune one model per task. To make the finetuning work, data curation (&gt;10k examples), training, deployment <strong>per task</strong> was the norm. GPT3 is a huge gamble. No one bothered training such a large model before. It’s a capital sink that could wreck a small company. Looking backward, the bet pays off very well. 2 lesson learned:</p>
<ol type="1">
<li>Scaling the same architecture with more data works better.</li>
<li>One LLM could perform many tasks with simple in-context learning.</li>
</ol>
<p>After gpt3, Chinchilla <span class="citation" data-cites="hoffmannTrainingComputeOptimalLarge2022">(<a href="#ref-hoffmannTrainingComputeOptimalLarge2022" role="doc-biblioref">Hoffmann et al. 2022</a>)</span>, Gopher <span class="citation" data-cites="raeScalingLanguageModels2022">(<a href="#ref-raeScalingLanguageModels2022" role="doc-biblioref">Rae et al. 2022</a>)</span>, PaLM <span class="citation" data-cites="chowdheryPaLMScalingLanguage2022">(<a href="#ref-chowdheryPaLMScalingLanguage2022" role="doc-biblioref">Chowdhery et al. 2022</a>)</span>, CoT <span class="citation" data-cites="weiChainThoughtPrompting2022">(<a href="#ref-weiChainThoughtPrompting2022" role="doc-biblioref">Wei et al. 2022</a>)</span>, SC <span class="citation" data-cites="wangSelfConsistencyImprovesChain2022a">(<a href="#ref-wangSelfConsistencyImprovesChain2022a" role="doc-biblioref">Wang et al. 2022</a>)</span> flourished.</p>
<p>The lesson of gpt4, especially how it’s presented in <span class="citation" data-cites="bubeckSparksArtificialGeneral2023">Bubeck et al. (<a href="#ref-bubeckSparksArtificialGeneral2023" role="doc-biblioref">2023</a>)</span>, is text only autoregressive model trained by next token prediction is actually learning a <strong>multimodal world model</strong>. Resonate perfectly with Ilya’s GPT23 talk:</p>
<blockquote class="blockquote">
<p>Next token prediction is actually learning some representations of the process that produce the texts, which is a projection of the world.</p>
</blockquote>
<p>This is a shocking revelation to me. I thought language model is just a huge joint distribution function, which happens to mimic some patterns in text. Turns out it’s more than that. Let’s take a look at few examples.</p>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="unicorn.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption margin-caption"><span class="citation" data-cites="bubeckSparksArtificialGeneral2023">(<a href="#ref-bubeckSparksArtificialGeneral2023" role="doc-biblioref">Bubeck et al. 2023, fig. 1.3</a>)</span></figcaption><p></p>
</figure>
</div>
<p>Seriously, how does LLM learn what unicorn looks like is still beyond me. Of course there are texts describing unicorns but it has never seen a picture and yet could still draw a better unicorn than me, in TeX?</p>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="artist.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption margin-caption"><span class="citation" data-cites="bubeckSparksArtificialGeneral2023">(<a href="#ref-bubeckSparksArtificialGeneral2023" role="doc-biblioref">Bubeck et al. 2023, fig. 2.1</a>)</span></figcaption><p></p>
</figure>
</div>
<p>This is even crazier. Out of uncountable names, gpt4 could recognize this artist name and somehow capture the gist of that artist’s style and use Javascript to render the picture. Speechless.</p>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="abc_person.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption margin-caption"><span class="citation" data-cites="bubeckSparksArtificialGeneral2023">(<a href="#ref-bubeckSparksArtificialGeneral2023" role="doc-biblioref">Bubeck et al. 2023, fig. 2.5</a>)</span></figcaption><p></p>
</figure>
</div>
<p>This one is more than a visual render. It combines the shape of English characters and the idea of the appearance of a person to generate a person, and the generation process is controllable by natural language instructions.</p>
<p>Astute readers would find the generation is secondary, meaning it’s not <code>fn(text) -&gt; pixel</code>, but <code>fn(text) -&gt; code -&gt; pixel</code>. However it’s reasonable to assume gpt4 has the visual idea of the unicorn to generate relevant codes for the render. Plus, a hidden benefit of such secondary generation that could be very useful.</p>
<p>Modern text to image models have trouble following instructions with specific composition. My hunch is text|image joint entropy learned from CLIP, used by latent diffusion<span class="citation" data-cites="rombachHighResolutionImageSynthesis2022">(<a href="#ref-rombachHighResolutionImageSynthesis2022" role="doc-biblioref">Rombach et al. 2022</a>)</span> is not fine grained enough to support precise language instruction. For example:</p>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="mj.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption margin-caption">MidJourney: three people in a row, one man in mid 40s on the left wearing a suit, holding an iphone, a yound lady in the middle, and a 6 year old boy wearing school uniform on the right. –ar 3:2</figcaption><p></p>
</figure>
</div>
<p>However, gpt4’s unreasonable effectiveness of text to code could repurpose code as intermediate symbolic layer for fine grained instruction guided image generation.</p>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="diffusion.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption margin-caption"><span class="citation" data-cites="bubeckSparksArtificialGeneral2023">(<a href="#ref-bubeckSparksArtificialGeneral2023" role="doc-biblioref">Bubeck et al. 2023, fig. 2.8</a>)</span></figcaption><p></p>
</figure>
</div>
<p>This combines the compositionality of natural language, and the pixel generation of diffusion. Win-win.</p>
<p>Examples above should be enough to reiterate that learning from text is not just about text. If you think about it, texts feed into transformer are sequence of integers, ex: [332, 5242, 12, 24325, …]. We feel so strong on the difference among modalities, such as image, audio, texts, because they are really different semantically to us, humans.</p>
<p>Behind the veil of human semantics, patterns of all modalities are all generated from the same source, this world. Yes text is secondary, interpreted patterns through humans, but it’s powerful and expressive, plus no other modalities to better represent the nuances of human conditions than texts, such that learning from text could actually yield a very useful world model.</p>
<p>The research community is talking about common sense, basic physics and unspoken multimodal knowledge. That’s why text is just the bootstrapping phase not the end of AI. The future has to be multimodal.</p>
</section>
<section id="self-improvement-with-rlhf" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="self-improvement-with-rlhf">Self improvement with RLHF</h3>
<blockquote class="blockquote">
<p>…there are benefits to squeezing as much performance as possible out of large generative image models, as significant semantic information may lie in the <code>last few bits</code></p>
<p>–<span class="citation" data-cites="henighanScalingLawsAutoregressive2020">Henighan et al. (<a href="#ref-henighanScalingLawsAutoregressive2020" role="doc-biblioref">2020</a>)</span></p>
</blockquote>
<p>The general improvement of gpt4 over gpt3.5 make self improvement possible. However, we need to pay attention to what could be self-improved, and how.</p>
<p>LLM’s raw capabilities are sealed during pretraining. Ensuing instruction finetuning and RLHF are usability improvement. Imagine a genius who doesn’t know how to talk to normal people. You may think he is dumb and slow but the raw power is there. Say he reads how to win friends and influence people and suddenly, people around him may think his IQ points doubled over a weekend, but no. He is just more accessible after finetuning.</p>
<p>Unlocked self-improvement has 2 folds: self-evaluation, and self-finetuning.<br>
There is no magic in self-evaluation. It’s not gpt4 has gained consciousness and grow the sense of self. GPT4 is stateless. Because it has learned few more bits than gpt3.5, it simple could evaluate whatever text better by following right prompts.</p>
<p>Here I want to use how OpenAI mitigates close domain <strong>hallucination</strong> with <strong>RLHF</strong> <span class="citation" data-cites="ouyangTrainingLanguageModels2022">(<a href="#ref-ouyangTrainingLanguageModels2022" role="doc-biblioref">Ouyang et al. 2022</a>)</span> as an example to illustrate how gpt4 contributes to self-improvement with the power of RL.</p>
<p>Take a look at the example of close and open hallucination.</p>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="hallucination_example.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption margin-caption"><span class="citation" data-cites="bubeckSparksArtificialGeneral2023">(<a href="#ref-bubeckSparksArtificialGeneral2023" role="doc-biblioref">Bubeck et al. 2023, fig. 1.8</a>)</span></figcaption><p></p>
</figure>
</div>
<p>OpenAI introduces a simple iterative procedure to apply gpt4 to evaluate its output and generate self correction.</p>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="hallucination.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption margin-caption"><span class="citation" data-cites="GPT4TechnicalReport">(<a href="#ref-GPT4TechnicalReport" role="doc-biblioref"><span>“<span>GPT-4</span> Technical Report”</span> 2023</a>, System Card, page 24)</span></figcaption><p></p>
</figure>
</div>
<p>The synthetic data is use to improve the mode via RLHF. (original response with hallucinations, new response without hallucination generated by gpt4) data are mixed into reward model dataset. This is RLHF</p>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="rlhf.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption margin-caption"><span class="citation" data-cites="ouyangTrainingLanguageModels2022">(<a href="#ref-ouyangTrainingLanguageModels2022" role="doc-biblioref">Ouyang et al. 2022, fig. 2</a>)</span></figcaption><p></p>
</figure>
</div>
<p>So on high level: SFT &gt; RM &gt; PPO. I don’t understand why initially. Super confused.</p>
<ul>
<li>Why RL?</li>
<li>If Flan <span class="citation" data-cites="chungScalingInstructionFinetunedLanguage2022">(<a href="#ref-chungScalingInstructionFinetunedLanguage2022" role="doc-biblioref">Chung et al. 2022</a>)</span> is so successful, why not just SFT gpt4 with generated hallucination free data?</li>
<li>Isn’t RL sample inefficient? Cherry on the cake? Sparse feedback makes credit assignment hard, which makes learning even harder? How many unreasonably amount of trials and errors to teach a simple robot in MoJoCo to run?</li>
</ul>
<p>My hypothesis is under the right condition, RL’s disadvantages are actually great for cooking intelligence.</p>
<ul>
<li>Good enough base intelligence.</li>
<li>Enough capacity to grow and change.</li>
</ul>
<p>Let me use human learning as an unscientific example. The goal is to maximize learning, which teacher is more helpful?</p>
<ul>
<li>One that provides extensive explanation, step by step reasoning, even hold your hand during the learning process.</li>
<li>One that only gives you binary feedback such as correct/incorrect, promising/exhausted, right direction/detour.</li>
</ul>
<p>On the appearance, the attentive teacher seems to be the obvious choice, but I realize it depends.</p>
<p>For young Padawan, rich feedbacks and hand holding style is more effective. They need as immersive environment as possible to get over the init stage. They would really struggle with sparse, succinct feedback. Socratic method or Zen style teaching is too early.</p>
<p>On the contrary, for matured enough Jedi to become true master, he has to tackle unknown unknown and generalize mostly by himself. Breaking the frontier can’t by achieved by copy previous success. Overly involved teaching is not helpful, but obstacle that creates a ceiling for the promising Jedi. The guidance could be vague and abstract as long as the direction is good, the student could figure out the details and apply general learnings to other challenges.</p>
<p>Autoregressive model with next token prediction is feedback rich learning. Every token contributes to loss, which signal for the change through back propagation. The process is super parallelizable and optimize that push all high quality text tokens on Earth through the model is doable. Text pretraining is effective intelligence bootstrapping.</p>
<p>After pretraining and essential finetunings, <code>gpt4-early</code> is large enough to take further finetuning without catastrophic forgetting, and intelligent enough to accept high level feedback, aka RLHF.</p>
<p>Even though synthetic data could be used for supervised finetuning, use them to improve reward model to take advantage of RL’s sparse feedback gives you the benefit of information bottleneck, a form of regularization that is even more sample efficient and generalizable. Yoda’s wise or even cryptic words may be confusing and not useful right on, but it points to problems behind a problem, which is more valuable to a smart Jedi looking backward.</p>
<p>Finetuning works better on LLM. RLHF would work better on LLM as well. Small model is not intelligent enough to deal with sparse feedback, and the capacity is too small to endure series of finetuning. GPT4 crosses both the intelligence and capacity threshold to kick start the virtuous self-improvement cycle with RLHF.</p>
</section>
</section>
<section id="future" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="future">Future</h2>
<section id="research" class="level3">
<h3 class="anchored" data-anchor-id="research">Research</h3>
<ul>
<li>Multimodal</li>
<li>System 2</li>
</ul>
<p>Firstly, if gpt4 could learn a world model with useful visual representation via such limited text projection, what could be learned from multimodal projection? Visual signals are so innate to humans that some ideas we don’t even bother putting them down in texts. It’s reasonable to assume multimodal learning, if done right, would yield more powerful representation and the learning would be more sample efficient. This is the cutting edge. Even OpenAI downplays the discussion on this topic, but it begs to wonder what if it’s possible to learn a better world model with &lt;20b params and &lt;1T multimodal tokens?</p>
<p>Secondly, the biggest limitation of gpt4 is planning. Current LLM is a stateless function. Autoregressive generation behaves like an iterative recursive process <span class="citation" data-cites="abelsonStructureInterpretationComputer1996">(<a href="#ref-abelsonStructureInterpretationComputer1996" role="doc-biblioref">Abelson, Sussman, and Sussman 1996, fig. 1.4</a>)</span>, keeping states in the argument, aka context window. How to get to system 2? How could long-term memory help? Using tools? Higher level control? Moving beyond next token prediction objective?</p>
</section>
<section id="human-ai-symbiosis" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="human-ai-symbiosis">Human-AI symbiosis</h3>
<p>Full list of risks from <strong>GPT-4 System Card</strong> <span class="citation" data-cites="GPT4TechnicalReport">(<a href="#ref-GPT4TechnicalReport" role="doc-biblioref"><span>“<span>GPT-4</span> Technical Report”</span> 2023</a>)</span>:</p>
<ul>
<li>Hallucinations</li>
<li>Harmful content</li>
<li>Harms of representation, allocation, and quality of service</li>
<li>Disinformation and influence operations</li>
<li>Proliferation of conventional and unconventional weapons</li>
<li>Privacy</li>
<li>Cybersecurity</li>
<li>Potential for risky emergent behaviors</li>
<li>Economic impacts</li>
<li>Acceleration</li>
<li>Overreliance</li>
</ul>
<p>Powerful models introduce serious problems. Helpful and harmless are nuanced if not contradictory balance. Even honest is not so trivial. I was not familiar with the full spectrum of risks introduced in the paper because of my ignorance, I mostly focused on capability upgrade like iPhone spec bump. Definitely recommend reading the system card in full to experience the width and depth of AI dark force.</p>
<p>What worries me the most is proliferation and acceleration. The danger of enabling simple minds with unrestricted powerful tools is obvious. Now with AI getting better and taking bigger role of evaluation and self-improvement, the speed of progress may be too fast for human to adapt. Dramatic change is in order. Social unrest is unavoidable. This is steam engine-electricity-internet level of change, even AI stops here with no further improvement.</p>
<p>More and more people are getting at the problem about what value AI should align to, who decides? These are right questions to ask. I hope the process of building ideal AI would force humans to rethink what it means to be a human? What’s the purpose? To what ends? What universal values we should get behind?</p>
<div class="page-columns page-full"><p>There would be Universal Declaration of Human Rights<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a> moment in the future that a group of people consciously choose a set of values as foundation of AI of the group. AI would be the most powerful creation of human civilization. I hope we could settle on a set of values that promotes peace, love and autonomy.</p><div class="no-row-height column-margin column-container"><li id="fn2"><p><sup>2</sup>&nbsp;<a href="https://www.un.org/en/about-us/universal-declaration-of-human-rights">https://www.un.org/en/about-us/universal-declaration-of-human-rights</a></p></li></div></div>
<p>Humans need to learn how to cap the downside and exploit the upside. Alignment research is hot and still underrated. No one wants to live in a world full of super intelligent assholes, to say the least.</p>
<p>For effective collaboration, we need to know who is better at what, and allocating resource accordingly.</p>
<ul>
<li>Incremental tasks: these are tasks which can be solved in a gradual or continuous way, by adding one word or sentence at a time that constitutes progress in the direction of the solution. Those tasks can be solved via content generation which does not require any major conceptual shifts or insights, but rather relies on applying existing knowledge and skills to the given topic or problem. Examples of incremental tasks are writing a summary of a text, answering factual questions, composing a poem based on a given rhyme scheme, or solving a math problem that follows a standard procedure.</li>
<li>Discontinuous tasks: these are tasks where the content generation cannot be done in a gradual or continuous way, but instead requires a certain ”Eureka” idea that accounts for a discontinuous leap in the progress towards the solution of the task. The content generation involves discovering or inventing a new way of looking at or framing the problem, that enables the generation of the rest of the content. Examples of discontinuous tasks are solving a math problem that requires a novel or creative application of a formula, writing a joke or a riddle, coming up with a scientific hypothesis or a philosophical argument, or creating a new genre or style of writing.</li>
</ul>
<p>It’s clear we need to identify and offload incremental work to AI. Cultivate creativity, critical thinking and intuitions that make the leap and connect seemingly irrelevant dots.</p>
<p>Working against AI is futile. Uncontrolled fear is waste of time.</p>
</section>
</section>
<section id="outro" class="level2">
<h2 class="anchored" data-anchor-id="outro">Outro</h2>
<blockquote class="blockquote">
<p>There are little white spaces, rare moments when randomness interact with your life that create a truly free space where you can make a choice. A bubble of agency.</p>
<p>–Westworld Season 3</p>
</blockquote>
<p>AI is hopeful and dangerous. As a tool, it’s a powerful amplifier. It would be a source of change. I hope, collectively we could drive it to afford more people with more space for making choices, improve the sense of agency, and autonomy.</p>
<p>I’ll close the article with one of my favorite quote:</p>
<blockquote class="blockquote">
<p>One pressing question woke him up every morning, as regularly as the screech of the whistle of the train that chugged by his cabin, on tracks built just up the hill from Walden Pond, where he’d hoped to still his soul. Were all these vast designs and rapid strides worth it? Thoreau thought not. He came to this truth: “They are but improved means to an unimproved end.”And still the trains chugged along, and the factories hummed, and the banks opened and closed, and the presses printed newspapers, and the telegraph wires reached across the nation, in one great and unending thrum.</p>
<p>– <cite>Jill Lepore, These Truths: A History of the United States</cite></p>
</blockquote>



</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" role="doc-bibliography">
<div id="ref-abelsonStructureInterpretationComputer1996" class="csl-entry" role="doc-biblioentry">
Abelson, Harold, Gerald Jay Sussman, and Julie Sussman. 1996. <em>Structure and <span>Interpretation</span> of <span>Computer Programs</span> - 2nd <span>Edition</span></em>. Second edition. <span>Cambridge, Mass.</span>: <span>The MIT Press</span>.
</div>
<div id="ref-brownLanguageModelsAre2020" class="csl-entry" role="doc-biblioentry">
Brown, Tom B., Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, et al. 2020. <span>“Language <span>Models</span> Are <span>Few-Shot Learners</span>.”</span> July 22, 2020. <a href="http://arxiv.org/abs/2005.14165">http://arxiv.org/abs/2005.14165</a>.
</div>
<div id="ref-bubeckSparksArtificialGeneral2023" class="csl-entry" role="doc-biblioentry">
Bubeck, Sébastien, Varun Chandrasekaran, Ronen Eldan, Johannes Gehrke, Eric Horvitz, Ece Kamar, Peter Lee, et al. 2023. <span>“Sparks of <span>Artificial General Intelligence</span>: <span>Early</span> Experiments with <span>GPT-4</span>.”</span> March 22, 2023. <a href="http://arxiv.org/abs/2303.12712">http://arxiv.org/abs/2303.12712</a>.
</div>
<div id="ref-chowdheryPaLMScalingLanguage2022" class="csl-entry" role="doc-biblioentry">
Chowdhery, Aakanksha, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, et al. 2022. <span>“<span>PaLM</span>: <span>Scaling Language Modeling</span> with <span>Pathways</span>,”</span> April. <a href="https://arxiv.org/abs/2204.02311v2">https://arxiv.org/abs/2204.02311v2</a>.
</div>
<div id="ref-chungScalingInstructionFinetunedLanguage2022" class="csl-entry" role="doc-biblioentry">
Chung, Hyung Won, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay, William Fedus, Eric Li, et al. 2022. <span>“Scaling <span>Instruction-Finetuned Language Models</span>.”</span> October 21, 2022. <a href="http://arxiv.org/abs/2210.11416">http://arxiv.org/abs/2210.11416</a>.
</div>
<div id="ref-eloundouGPTsAreGPTs2023" class="csl-entry" role="doc-biblioentry">
Eloundou, Tyna, Sam Manning, Pamela Mishkin, and Daniel Rock. 2023. <span>“<span>GPTs</span> Are <span>GPTs</span>: <span>An Early Look</span> at the <span>Labor Market Impact Potential</span> of <span>Large Language Models</span>.”</span> March 21, 2023. <a href="http://arxiv.org/abs/2303.10130">http://arxiv.org/abs/2303.10130</a>.
</div>
<div id="ref-GPT4TechnicalReport" class="csl-entry" role="doc-biblioentry">
<span>“<span>GPT-4</span> Technical Report.”</span> 2023. March 14, 2023. <a href="https://openai.com/research/gpt-4">https://openai.com/research/gpt-4</a>.
</div>
<div id="ref-henighanScalingLawsAutoregressive2020" class="csl-entry" role="doc-biblioentry">
Henighan, Tom, Jared Kaplan, Mor Katz, Mark Chen, Christopher Hesse, Jacob Jackson, Heewoo Jun, et al. 2020. <span>“Scaling <span>Laws</span> for <span>Autoregressive Generative Modeling</span>.”</span> November 5, 2020. <a href="http://arxiv.org/abs/2010.14701">http://arxiv.org/abs/2010.14701</a>.
</div>
<div id="ref-hoffmannTrainingComputeOptimalLarge2022" class="csl-entry" role="doc-biblioentry">
Hoffmann, Jordan, Sebastian Borgeaud, Arthur Mensch, Elena Buchatskaya, Trevor Cai, Eliza Rutherford, Diego de Las Casas, et al. 2022. <span>“Training <span>Compute-Optimal Large Language Models</span>.”</span> <a href="http://arxiv.org/abs/2203.15556">http://arxiv.org/abs/2203.15556</a>.
</div>
<div id="ref-lexfridmanSamAltmanOpenAI2023" class="csl-entry" role="doc-biblioentry">
Lex Fridman, dir. 2023. <em>Sam <span>Altman</span>: <span>OpenAI CEO</span> on <span>GPT-4</span>, <span>ChatGPT</span>, and the <span>Future</span> of <span>AI</span> | <span>Lex Fridman Podcast</span> #367</em>. <a href="https://www.youtube.com/watch?v=L_Guz73e6fw">https://www.youtube.com/watch?v=L_Guz73e6fw</a>.
</div>
<div id="ref-ouyangTrainingLanguageModels2022" class="csl-entry" role="doc-biblioentry">
Ouyang, Long, Jeff Wu, Xu Jiang, Diogo Almeida, Carroll L. Wainwright, Pamela Mishkin, Chong Zhang, et al. 2022. <span>“Training Language Models to Follow Instructions with Human Feedback,”</span> March. <a href="https://arxiv.org/abs/2203.02155v1">https://arxiv.org/abs/2203.02155v1</a>.
</div>
<div id="ref-raeScalingLanguageModels2022" class="csl-entry" role="doc-biblioentry">
Rae, Jack W., Sebastian Borgeaud, Trevor Cai, Katie Millican, Jordan Hoffmann, Francis Song, John Aslanides, et al. 2022. <span>“Scaling <span>Language Models</span>: <span>Methods</span>, <span>Analysis</span> &amp; <span>Insights</span> from <span>Training Gopher</span>.”</span> <a href="http://arxiv.org/abs/2112.11446">http://arxiv.org/abs/2112.11446</a>.
</div>
<div id="ref-rombachHighResolutionImageSynthesis2022" class="csl-entry" role="doc-biblioentry">
Rombach, Robin, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Björn Ommer. 2022. <span>“High-<span>Resolution Image Synthesis</span> with <span>Latent Diffusion Models</span>.”</span> April 13, 2022. <a href="http://arxiv.org/abs/2112.10752">http://arxiv.org/abs/2112.10752</a>.
</div>
<div id="ref-silverMasteringChessShogi2017" class="csl-entry" role="doc-biblioentry">
Silver, David, Thomas Hubert, Julian Schrittwieser, Ioannis Antonoglou, Matthew Lai, Arthur Guez, Marc Lanctot, et al. 2017. <span>“Mastering <span>Chess</span> and <span>Shogi</span> by <span>Self-Play</span> with a <span>General Reinforcement Learning Algorithm</span>.”</span> December 5, 2017. <a href="http://arxiv.org/abs/1712.01815">http://arxiv.org/abs/1712.01815</a>.
</div>
<div id="ref-sutskeverFiresideChatIlya2023" class="csl-entry" role="doc-biblioentry">
Sutskever, Ilya, and Jensen Huang. 2023. <span>“Fireside <span>Chat</span> with <span>Ilya Sutskever</span> and <span>Jensen Huang</span>: <span>AI Today</span> and <span>Vision</span> of the <span>Future</span>.”</span> March 23, 2023. <a href="https://register.nvidia.com/flow/nvidia/gtcspring2023/attendeeportal/page/sessioncatalog/session/1669748941314001t6Nv">https://register.nvidia.com/flow/nvidia/gtcspring2023/attendeeportal/page/sessioncatalog/session/1669748941314001t6Nv</a>.
</div>
<div id="ref-wangSelfConsistencyImprovesChain2022a" class="csl-entry" role="doc-biblioentry">
Wang, Xuezhi, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, Sharan Narang, Aakanksha Chowdhery, and Denny Zhou. 2022. <span>“Self-<span>Consistency Improves Chain</span> of <span>Thought Reasoning</span> in <span>Language Models</span>.”</span> October 4, 2022. <a href="http://arxiv.org/abs/2203.11171">http://arxiv.org/abs/2203.11171</a>.
</div>
<div id="ref-weiChainThoughtPrompting2022" class="csl-entry" role="doc-biblioentry">
Wei, Jason, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian Ichter, Fei Xia, Ed Chi, Quoc Le, and Denny Zhou. 2022. <span>“Chain of <span>Thought Prompting Elicits Reasoning</span> in <span>Large Language Models</span>.”</span> January 28, 2022. <a href="https://arxiv.org/abs/2201.11903v5">https://arxiv.org/abs/2201.11903v5</a>.
</div>
</div></section><section class="quarto-appendix-contents"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{shen2023,
  author = {Lucas Shen},
  title = {On {GPT4}},
  date = {2023-04-01},
  url = {https://lukaemon.github.io/posts/2023/on-gpt4},
  langid = {en}
}
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-shen2023" class="csl-entry quarto-appendix-citeas" role="doc-biblioentry">
Lucas Shen. 2023. <span>“On GPT4.”</span> April 1, 2023. <a href="https://lukaemon.github.io/posts/2023/on-gpt4">https://lukaemon.github.io/posts/2023/on-gpt4</a>.
</div></div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  let localAlternateSentinel = 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>