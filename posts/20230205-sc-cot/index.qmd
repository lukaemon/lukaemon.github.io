---
title: "Self-consistency and chain of thought"
description: Lesson learned from CoT and SC. 
date: "2023-02-05"
categories: [AI]
image: "sc.png"
---
![](sc.png)

## Reasoning and natural language understanding
[Scaling Language Models: Methods, Analysis & Insights from Training Gopher](http://arxiv.org/abs/2112.11446) mention flat scaling curve of few task categories, google has been very creative to push the frontier with `CoT`, `SC`, `least to most` and so on.

> Scale has a reduced benefit for tasks in the Maths, Logical Reasoning, and Common Sense categories. Our results suggest that for certain flavours of mathematical or logical reasoning tasks, it is unlikely that scale alone will lead to performance breakthroughs. 
 
`Informal reasoning` would be solved, and there is a reason why google, DeepMind and OpenAI are all into solving `formal reasoning`. That's the last frontier wrt reasoning if AI could get logic and math right.

`Codex` family model is the first step on solving formal reasoning. In SC and BBH paper, `code-davinci-002` performs better than `InstructGPT` families on reasoning tasks. DeepMind even dive into `GNN` to explore different architecture other than transformer. Reasoning in general would be solved as a modality in near future. It may require a specialized model, but would ultimately be fused into general LLM like image, audio and the like. 

[Scaling Laws for Autoregressive Generative Modeling](http://arxiv.org/abs/2010.14701):

> The approach to the `irreducible loss` does not necessarily indicate diminishing returns for representation quality or semantic content as **significant semantic information may lie in the last few bits**.

To get natural language understanding right, scale is necessary. This also explains why CoT only works with scale. Small model makes too many semantic mistakes that render scaling computation with CoT worthless to get things right. SC could cancel out mistakes by majority vote and improve performance for model of all size but the increased computational cost out weight possible performance gain for small model. `Self-ensemble` weak reasoner is waste of resource. 

## Retrieval augmented LM
Scale may not be the most effective method to solve `world knowledge` problem. 1T param model may get the `last few bit of semantics` but won't get the facts 100% right. That's why `retrieval` is necessary. One could treat external knowledge database as a modality and figure out how to fuse it with general LLM. 

Think about how existing multimodal model fuses modalities, ex: `Dall-E`, `Stable Diffusion`, `MusicLM` and so on. [RETRO](http://arxiv.org/abs/2112.04426) is a great example of treating external memory as modality and try to fuse it with general LM deeply. Of course it's not plug and play but an interesting research direction.

`In-context retrieval` dominates current research output because of light resource requirement. Its value is like `prompt engineering`: the most effective method to probe LLM to find new gains of performance, but prompt engineering would never be the ultimate solution. It's a tentative exploration process. Like instruction finetuning makes LLM follow human instruction and do CoT in 0 shot, rather than few shot, `RETRO` like solution may render methods such as [Recitation-Augmented Language Models](http://arxiv.org/abs/2210.01296) unnecessary. However, that is one great first step into retrieval world, like CoT as the first step into `rationale engineering`. 

## Building application
The point is not all-in 100b+ LLM, all-in `text-davinci-003`, but finding a way to fuse modalities. Small model like `T5-11b`, yes 11b is the new small lol, is still important for controlling latency and cost. Imagine doing 40 path `SC` on a 540b model per response for interactive UX. Not idea. A good production example: [Neeva with T5 to serve ChatGPT like search experience](https://twitter.com/ramaswmysridhar/status/1621870491945533440?s=12&t=nyAGas8S6bDKS1eLUw9I7Q). 

Multimodal is ongoing, on fire research field. One big end to end model may be enough like `Gato`. Modular approach with glue architecture may work like `Flamingo`. It's great to be alive in this era of AI.
